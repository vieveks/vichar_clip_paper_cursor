{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uqEeJrY7yo4n",
    "outputId": "b3ad8f05-8092-4d1d-f379-b72b436c062e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/cu121\n",
      "Requirement already satisfied: torch in c:\\users\\admin\\miniconda3\\envs\\pytorch_5070ti\\lib\\site-packages (2.9.0.dev20250813+cu128)\n",
      "Requirement already satisfied: torchvision in c:\\users\\admin\\miniconda3\\envs\\pytorch_5070ti\\lib\\site-packages (0.24.0.dev20250815+cu128)\n",
      "Requirement already satisfied: torchaudio in c:\\users\\admin\\miniconda3\\envs\\pytorch_5070ti\\lib\\site-packages (2.8.0.dev20250815+cu128)\n",
      "Requirement already satisfied: filelock in c:\\users\\admin\\miniconda3\\envs\\pytorch_5070ti\\lib\\site-packages (from torch) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\admin\\miniconda3\\envs\\pytorch_5070ti\\lib\\site-packages (from torch) (4.14.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\admin\\miniconda3\\envs\\pytorch_5070ti\\lib\\site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in c:\\users\\admin\\miniconda3\\envs\\pytorch_5070ti\\lib\\site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\admin\\miniconda3\\envs\\pytorch_5070ti\\lib\\site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in c:\\users\\admin\\miniconda3\\envs\\pytorch_5070ti\\lib\\site-packages (from torch) (2025.3.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\admin\\miniconda3\\envs\\pytorch_5070ti\\lib\\site-packages (from torchvision) (2.1.2)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\admin\\miniconda3\\envs\\pytorch_5070ti\\lib\\site-packages (from torchvision) (11.3.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\admin\\miniconda3\\envs\\pytorch_5070ti\\lib\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\admin\\miniconda3\\envs\\pytorch_5070ti\\lib\\site-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: ftfy in c:\\users\\admin\\miniconda3\\envs\\pytorch_5070ti\\lib\\site-packages (6.3.1)\n",
      "Requirement already satisfied: regex in c:\\users\\admin\\miniconda3\\envs\\pytorch_5070ti\\lib\\site-packages (2025.7.34)\n",
      "Requirement already satisfied: tqdm in c:\\users\\admin\\miniconda3\\envs\\pytorch_5070ti\\lib\\site-packages (4.67.1)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\admin\\miniconda3\\envs\\pytorch_5070ti\\lib\\site-packages (from ftfy) (0.2.13)\n",
      "Requirement already satisfied: colorama in c:\\users\\admin\\miniconda3\\envs\\pytorch_5070ti\\lib\\site-packages (from tqdm) (0.4.6)\n",
      "Requirement already satisfied: chess in c:\\users\\admin\\miniconda3\\envs\\pytorch_5070ti\\lib\\site-packages (1.11.2)\n",
      "Requirement already satisfied: cairosvg in c:\\users\\admin\\miniconda3\\envs\\pytorch_5070ti\\lib\\site-packages (2.8.2)\n",
      "Requirement already satisfied: pillow in c:\\users\\admin\\miniconda3\\envs\\pytorch_5070ti\\lib\\site-packages (11.3.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\admin\\miniconda3\\envs\\pytorch_5070ti\\lib\\site-packages (2.1.2)\n",
      "Requirement already satisfied: pandas in c:\\users\\admin\\miniconda3\\envs\\pytorch_5070ti\\lib\\site-packages (2.3.1)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\admin\\miniconda3\\envs\\pytorch_5070ti\\lib\\site-packages (3.10.5)\n",
      "Requirement already satisfied: cairocffi in c:\\users\\admin\\miniconda3\\envs\\pytorch_5070ti\\lib\\site-packages (from cairosvg) (1.7.1)\n",
      "Requirement already satisfied: cssselect2 in c:\\users\\admin\\miniconda3\\envs\\pytorch_5070ti\\lib\\site-packages (from cairosvg) (0.8.0)\n",
      "Requirement already satisfied: defusedxml in c:\\users\\admin\\miniconda3\\envs\\pytorch_5070ti\\lib\\site-packages (from cairosvg) (0.7.1)\n",
      "Requirement already satisfied: tinycss2 in c:\\users\\admin\\miniconda3\\envs\\pytorch_5070ti\\lib\\site-packages (from cairosvg) (1.4.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\admin\\miniconda3\\envs\\pytorch_5070ti\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\admin\\miniconda3\\envs\\pytorch_5070ti\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\admin\\miniconda3\\envs\\pytorch_5070ti\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\admin\\miniconda3\\envs\\pytorch_5070ti\\lib\\site-packages (from matplotlib) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\admin\\miniconda3\\envs\\pytorch_5070ti\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\admin\\miniconda3\\envs\\pytorch_5070ti\\lib\\site-packages (from matplotlib) (4.59.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\admin\\miniconda3\\envs\\pytorch_5070ti\\lib\\site-packages (from matplotlib) (1.4.9)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\admin\\miniconda3\\envs\\pytorch_5070ti\\lib\\site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\admin\\miniconda3\\envs\\pytorch_5070ti\\lib\\site-packages (from matplotlib) (3.2.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\admin\\miniconda3\\envs\\pytorch_5070ti\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: cffi>=1.1.0 in c:\\users\\admin\\miniconda3\\envs\\pytorch_5070ti\\lib\\site-packages (from cairocffi->cairosvg) (1.17.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\admin\\miniconda3\\envs\\pytorch_5070ti\\lib\\site-packages (from cffi>=1.1.0->cairocffi->cairosvg) (2.22)\n",
      "Requirement already satisfied: webencodings in c:\\users\\admin\\miniconda3\\envs\\pytorch_5070ti\\lib\\site-packages (from cssselect2->cairosvg) (0.5.1)\n",
      "Collecting git+https://github.com/openai/CLIP.git\n",
      "  Cloning https://github.com/openai/CLIP.git to c:\\users\\admin\\appdata\\local\\temp\\pip-req-build-7m4r7o4j\n",
      "  Resolved https://github.com/openai/CLIP.git to commit dcba3cb2e2827b402d2701e7e1c7d9fed8a20ef1\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: ftfy in c:\\users\\admin\\miniconda3\\envs\\pytorch_5070ti\\lib\\site-packages (from clip==1.0) (6.3.1)\n",
      "Requirement already satisfied: packaging in c:\\users\\admin\\miniconda3\\envs\\pytorch_5070ti\\lib\\site-packages (from clip==1.0) (25.0)\n",
      "Requirement already satisfied: regex in c:\\users\\admin\\miniconda3\\envs\\pytorch_5070ti\\lib\\site-packages (from clip==1.0) (2025.7.34)\n",
      "Requirement already satisfied: tqdm in c:\\users\\admin\\miniconda3\\envs\\pytorch_5070ti\\lib\\site-packages (from clip==1.0) (4.67.1)\n",
      "Requirement already satisfied: torch in c:\\users\\admin\\miniconda3\\envs\\pytorch_5070ti\\lib\\site-packages (from clip==1.0) (2.9.0.dev20250813+cu128)\n",
      "Requirement already satisfied: torchvision in c:\\users\\admin\\miniconda3\\envs\\pytorch_5070ti\\lib\\site-packages (from clip==1.0) (0.24.0.dev20250815+cu128)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\admin\\miniconda3\\envs\\pytorch_5070ti\\lib\\site-packages (from ftfy->clip==1.0) (0.2.13)\n",
      "Requirement already satisfied: filelock in c:\\users\\admin\\miniconda3\\envs\\pytorch_5070ti\\lib\\site-packages (from torch->clip==1.0) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\admin\\miniconda3\\envs\\pytorch_5070ti\\lib\\site-packages (from torch->clip==1.0) (4.14.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\admin\\miniconda3\\envs\\pytorch_5070ti\\lib\\site-packages (from torch->clip==1.0) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in c:\\users\\admin\\miniconda3\\envs\\pytorch_5070ti\\lib\\site-packages (from torch->clip==1.0) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\admin\\miniconda3\\envs\\pytorch_5070ti\\lib\\site-packages (from torch->clip==1.0) (3.1.6)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in c:\\users\\admin\\miniconda3\\envs\\pytorch_5070ti\\lib\\site-packages (from torch->clip==1.0) (2025.3.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\admin\\miniconda3\\envs\\pytorch_5070ti\\lib\\site-packages (from sympy>=1.13.3->torch->clip==1.0) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\admin\\miniconda3\\envs\\pytorch_5070ti\\lib\\site-packages (from jinja2->torch->clip==1.0) (3.0.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\admin\\miniconda3\\envs\\pytorch_5070ti\\lib\\site-packages (from torchvision->clip==1.0) (2.1.2)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\admin\\miniconda3\\envs\\pytorch_5070ti\\lib\\site-packages (from torchvision->clip==1.0) (11.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\admin\\miniconda3\\envs\\pytorch_5070ti\\lib\\site-packages (from tqdm->clip==1.0) (0.4.6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Running command git clone --filter=blob:none --quiet https://github.com/openai/CLIP.git 'C:\\Users\\admin\\AppData\\Local\\Temp\\pip-req-build-7m4r7o4j'\n"
     ]
    }
   ],
   "source": [
    "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\n",
    "!pip install ftfy regex tqdm\n",
    "!pip install chess cairosvg pillow numpy pandas matplotlib\n",
    "!pip install git+https://github.com/openai/CLIP.git\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatgpt_Clip.ipynb\n",
      "checkpoints\n",
      "checkpoints.zip\n",
      "dataset_loader.py\n",
      "dataset_prep.py\n",
      "download_pgn.py\n",
      "lichess_games_2013-01.pgn\n",
      "train_clip.py\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Aug 20 14:50:14 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 576.88                 Driver Version: 576.88         CUDA Version: 12.9     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                  Driver-Model | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GeForce RTX 5070 Ti   WDDM  |   00000000:01:00.0  On |                  N/A |\n",
      "|  0%   48C    P5             35W /  300W |    1961MiB /  16303MiB |      2%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A            2060    C+G   ...0.3405.102\\msedgewebview2.exe      N/A      |\n",
      "|    0   N/A  N/A            2672    C+G   ...Chrome\\Application\\chrome.exe      N/A      |\n",
      "|    0   N/A  N/A            3032    C+G   ...2txyewy\\CrossDeviceResume.exe      N/A      |\n",
      "|    0   N/A  N/A            5980    C+G   ..._cw5n1h2txyewy\\SearchHost.exe      N/A      |\n",
      "|    0   N/A  N/A            7184    C+G   ...indows\\System32\\ShellHost.exe      N/A      |\n",
      "|    0   N/A  N/A            8968    C+G   ...Chrome\\Application\\chrome.exe      N/A      |\n",
      "|    0   N/A  N/A            9560    C+G   ...IA App\\CEF\\NVIDIA Overlay.exe      N/A      |\n",
      "|    0   N/A  N/A           10088    C+G   ...__kzh8wxbdkxb8p\\DCv2\\DCv2.exe      N/A      |\n",
      "|    0   N/A  N/A           13588    C+G   ...m Files\\Obsidian\\Obsidian.exe      N/A      |\n",
      "|    0   N/A  N/A           13856    C+G   ...ntrolPanel\\SystemSettings.exe      N/A      |\n",
      "|    0   N/A  N/A           17324    C+G   ...0.3405.102\\msedgewebview2.exe      N/A      |\n",
      "|    0   N/A  N/A           21664    C+G   ...Chrome\\Application\\chrome.exe      N/A      |\n",
      "|    0   N/A  N/A           22868    C+G   ...IA App\\CEF\\NVIDIA Overlay.exe      N/A      |\n",
      "|    0   N/A  N/A           25268    C+G   ...em32\\ApplicationFrameHost.exe      N/A      |\n",
      "|    0   N/A  N/A           27192    C+G   ...y\\StartMenuExperienceHost.exe      N/A      |\n",
      "|    0   N/A  N/A           27244    C+G   C:\\Windows\\explorer.exe               N/A      |\n",
      "|    0   N/A  N/A           29556    C+G   ...8bbwe\\PhoneExperienceHost.exe      N/A      |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eX-ebTat21jn",
    "outputId": "a2afa9e4-1942-4829-98cd-dfd8fe6a03de"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting download_pgn.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile download_pgn.py\n",
    "import requests\n",
    "import zstandard as zstd\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import logging\n",
    "\n",
    "# Setup basic logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "def download_lichess_pgn(year: int, month: int, save_path: str = \".\"):\n",
    "    \"\"\"\n",
    "    Downloads and decompresses a monthly PGN file from the Lichess Open Database.\n",
    "    This version handles the modern .zst compression format.\n",
    "\n",
    "    Args:\n",
    "        year (int): The year of the games to download (e.g., 2022).\n",
    "        month (int): The month of the games to download (1-12).\n",
    "        save_path (str): The directory where the final PGN file will be saved.\n",
    "    \"\"\"\n",
    "    # Format the month to be two digits (e.g., 7 -> 07)\n",
    "    month_str = f\"{month:02d}\"\n",
    "\n",
    "    # Construct the URL for the .zst compressed PGN file\n",
    "    url = f\"https://database.lichess.org/standard/lichess_db_standard_rated_{year}-{month_str}.pgn.zst\"\n",
    "\n",
    "    compressed_file_name = os.path.join(save_path, f\"lichess_games_{year}-{month_str}.pgn.zst\")\n",
    "    decompressed_file_name = os.path.join(save_path, f\"lichess_games_{year}-{month_str}.pgn\")\n",
    "\n",
    "    logging.info(f\"Target URL: {url}\")\n",
    "\n",
    "    try:\n",
    "        # --- Step 1: Download the compressed file ---\n",
    "        logging.info(f\"Downloading from {url}...\")\n",
    "        response = requests.get(url, stream=True)\n",
    "        response.raise_for_status()  # Raise an exception for bad status codes (like 404)\n",
    "\n",
    "        total_size = int(response.headers.get('content-length', 0))\n",
    "\n",
    "        with open(compressed_file_name, 'wb') as f, tqdm(\n",
    "            desc=f\"Downloading {os.path.basename(compressed_file_name)}\",\n",
    "            total=total_size,\n",
    "            unit='iB',\n",
    "            unit_scale=True,\n",
    "            unit_divisor=1024,\n",
    "        ) as bar:\n",
    "            for chunk in response.iter_content(chunk_size=8192):\n",
    "                f.write(chunk)\n",
    "                bar.update(len(chunk))\n",
    "\n",
    "        logging.info(f\"Successfully downloaded to {compressed_file_name}\")\n",
    "\n",
    "        # --- Step 2: Decompress the .zst file ---\n",
    "        logging.info(f\"Decompressing {compressed_file_name}...\")\n",
    "\n",
    "        dctx = zstd.ZstdDecompressor()\n",
    "        with open(compressed_file_name, 'rb') as in_file, open(decompressed_file_name, 'wb') as out_file:\n",
    "            # Use a stream reader for efficient, chunked decompression\n",
    "            reader = dctx.stream_reader(in_file)\n",
    "            # Get the file size for the progress bar if possible (requires seeking)\n",
    "            in_file.seek(0, os.SEEK_END)\n",
    "            file_size = in_file.tell()\n",
    "            in_file.seek(0)\n",
    "\n",
    "            with tqdm(total=file_size, desc=f\"Decompressing {os.path.basename(decompressed_file_name)}\", unit='iB', unit_scale=True) as pbar:\n",
    "                while True:\n",
    "                    chunk = reader.read(16384) # Read in 16KB chunks\n",
    "                    if not chunk:\n",
    "                        break\n",
    "                    out_file.write(chunk)\n",
    "                    pbar.update(in_file.tell() - pbar.n) # Update progress based on input file read\n",
    "\n",
    "        logging.info(f\"✅ Successfully decompressed to {decompressed_file_name}\")\n",
    "\n",
    "        # --- Step 3: Clean up the compressed file ---\n",
    "        os.remove(compressed_file_name)\n",
    "        logging.info(f\"Removed temporary file: {compressed_file_name}\")\n",
    "\n",
    "    except requests.exceptions.HTTPError as e:\n",
    "        logging.error(f\"Error: Could not download the file. Status code: {e.response.status_code}\")\n",
    "        logging.error(\"Please check that the year and month are valid on the Lichess Database page: https://database.lichess.org/\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"An unexpected error occurred: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # --- Example Usage ---\n",
    "    # Let's download a recent, smaller file for testing, e.g., from the current year.\n",
    "    # We'll use January 2024 as an example.\n",
    "    target_year = 2013\n",
    "    target_month = 1\n",
    "\n",
    "    output_directory = \".\" # Save to the current directory\n",
    "\n",
    "    # Create the directory if it doesn't exist\n",
    "    if not os.path.exists(output_directory):\n",
    "        os.makedirs(output_directory)\n",
    "\n",
    "    download_lichess_pgn(target_year, target_month, output_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Bi85TSQ327lU",
    "outputId": "eb831f0e-7ced-4876-d168-a7b198cc9582"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: zstandard in c:\\users\\admin\\miniconda3\\envs\\pytorch_5070ti\\lib\\site-packages (0.24.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install zstandard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hHKvgCi82_jm",
    "outputId": "2e41f1f8-732c-4911-9e76-2bcdc73ace36"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-20 14:50:26,300 - INFO - Target URL: https://database.lichess.org/standard/lichess_db_standard_rated_2013-01.pgn.zst\n",
      "2025-08-20 14:50:26,300 - INFO - Downloading from https://database.lichess.org/standard/lichess_db_standard_rated_2013-01.pgn.zst...\n",
      "\n",
      "Downloading lichess_games_2013-01.pgn.zst:   0%|          | 0.00/16.9M [00:00<?, ?iB/s]\n",
      "Downloading lichess_games_2013-01.pgn.zst:   0%|          | 32.0k/16.9M [00:00<01:09, 254kiB/s]\n",
      "Downloading lichess_games_2013-01.pgn.zst:   0%|          | 80.0k/16.9M [00:00<00:56, 314kiB/s]\n",
      "Downloading lichess_games_2013-01.pgn.zst:   1%|1         | 176k/16.9M [00:00<00:36, 488kiB/s] \n",
      "Downloading lichess_games_2013-01.pgn.zst:   2%|2         | 368k/16.9M [00:00<00:19, 891kiB/s]\n",
      "Downloading lichess_games_2013-01.pgn.zst:   4%|4         | 752k/16.9M [00:00<00:10, 1.63MiB/s]\n",
      "Downloading lichess_games_2013-01.pgn.zst:   9%|8         | 1.50M/16.9M [00:00<00:05, 3.08MiB/s]\n",
      "Downloading lichess_games_2013-01.pgn.zst:  15%|#4        | 2.50M/16.9M [00:00<00:03, 4.54MiB/s]\n",
      "Downloading lichess_games_2013-01.pgn.zst:  25%|##5       | 4.27M/16.9M [00:01<00:01, 8.04MiB/s]\n",
      "Downloading lichess_games_2013-01.pgn.zst:  32%|###1      | 5.36M/16.9M [00:01<00:01, 8.90MiB/s]\n",
      "Downloading lichess_games_2013-01.pgn.zst:  44%|####3     | 7.38M/16.9M [00:01<00:00, 12.2MiB/s]\n",
      "Downloading lichess_games_2013-01.pgn.zst:  54%|#####3    | 9.12M/16.9M [00:01<00:00, 13.9MiB/s]\n",
      "Downloading lichess_games_2013-01.pgn.zst:  64%|######3   | 10.8M/16.9M [00:01<00:00, 14.8MiB/s]\n",
      "Downloading lichess_games_2013-01.pgn.zst:  76%|#######5  | 12.8M/16.9M [00:01<00:00, 16.5MiB/s]\n",
      "Downloading lichess_games_2013-01.pgn.zst:  85%|########5 | 14.5M/16.9M [00:01<00:00, 16.7MiB/s]\n",
      "Downloading lichess_games_2013-01.pgn.zst:  98%|#########7| 16.5M/16.9M [00:01<00:00, 18.2MiB/s]\n",
      "Downloading lichess_games_2013-01.pgn.zst: 100%|##########| 16.9M/16.9M [00:01<00:00, 9.97MiB/s]\n",
      "2025-08-20 14:50:28,636 - INFO - Successfully downloaded to .\\lichess_games_2013-01.pgn.zst\n",
      "2025-08-20 14:50:28,636 - INFO - Decompressing .\\lichess_games_2013-01.pgn.zst...\n",
      "\n",
      "Decompressing lichess_games_2013-01.pgn:   0%|          | 0.00/17.8M [00:00<?, ?iB/s]\n",
      "Decompressing lichess_games_2013-01.pgn:  86%|########6 | 15.3M/17.8M [00:00<00:00, 153MiB/s]\n",
      "Decompressing lichess_games_2013-01.pgn: 100%|##########| 17.8M/17.8M [00:00<00:00, 154MiB/s]\n",
      "2025-08-20 14:50:28,764 - INFO - \\u2705 Successfully decompressed to .\\lichess_games_2013-01.pgn\n",
      "2025-08-20 14:50:28,765 - INFO - Removed temporary file: .\\lichess_games_2013-01.pgn.zst\n"
     ]
    }
   ],
   "source": [
    "!python download_pgn.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wi-8xTVk4kp1",
    "outputId": "29e7efce-ed4c-4ecc-e725-f06df87b4c71"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing dataset_prep.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile dataset_prep.py\n",
    "import chess.pgn\n",
    "import chess.svg\n",
    "import cairosvg\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import logging\n",
    "\n",
    "# Setup basic logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "def pgn_to_examples(pgn_path: str, out_dir: str, max_games: int = 1000):\n",
    "    \"\"\"\n",
    "    Processes a PGN file to generate image-text pairs for training a CLIP model on chess positions.\n",
    "\n",
    "    Args:\n",
    "        pgn_path (str): Path to the input PGN file.\n",
    "        out_dir (str): The root directory to save the generated datasets.\n",
    "        max_games (int): The maximum number of games to process from the PGN file.\n",
    "    \"\"\"\n",
    "    out_dir = Path(out_dir)\n",
    "    fen_only_dir = out_dir / \"fen_only\"\n",
    "    fen_move_dir = out_dir / \"fen_move\"\n",
    "\n",
    "    # Create directories if they don't exist\n",
    "    fen_only_dir.mkdir(parents=True, exist_ok=True)\n",
    "    (fen_only_dir / \"images\").mkdir(exist_ok=True)\n",
    "    (fen_only_dir / \"texts\").mkdir(exist_ok=True)\n",
    "\n",
    "    fen_move_dir.mkdir(parents=True, exist_ok=True)\n",
    "    (fen_move_dir / \"images\").mkdir(exist_ok=True)\n",
    "    (fen_move_dir / \"texts\").mkdir(exist_ok=True)\n",
    "\n",
    "    try:\n",
    "        with open(pgn_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            idx = 0\n",
    "            for _ in tqdm(range(max_games), desc=\"Processing games\"):\n",
    "                game = chess.pgn.read_game(f)\n",
    "                if game is None:\n",
    "                    logging.warning(\"No more games found in PGN file.\")\n",
    "                    break\n",
    "\n",
    "                board = game.board()\n",
    "                for move in game.mainline_moves():\n",
    "                    fen = board.fen()\n",
    "                    move_uci = move.uci()\n",
    "\n",
    "                    # Generate and save the board image\n",
    "                    svg_data = chess.svg.board(board=board, size=350)\n",
    "                    try:\n",
    "                        png_bytes = cairosvg.svg2png(bytestring=svg_data.encode(\"utf-8\"))\n",
    "\n",
    "                        # Save image for FEN only dataset\n",
    "                        img_path_fen_only = fen_only_dir / \"images\" / f\"{idx}.png\"\n",
    "                        with open(img_path_fen_only, \"wb\") as img_file:\n",
    "                            img_file.write(png_bytes)\n",
    "\n",
    "                        # Save image for FEN + move dataset\n",
    "                        img_path_fen_move = fen_move_dir / \"images\" / f\"{idx}.png\"\n",
    "                        with open(img_path_fen_move, \"wb\") as img_file:\n",
    "                            img_file.write(png_bytes)\n",
    "\n",
    "                    except Exception as e:\n",
    "                        logging.error(f\"Failed to convert SVG to PNG for position at index {idx}: {e}\")\n",
    "                        continue\n",
    "\n",
    "                    # Version A: Save FEN only\n",
    "                    with open(fen_only_dir / \"texts\" / f\"{idx}.txt\", \"w\", encoding=\"utf-8\") as ftxt:\n",
    "                        ftxt.write(fen)\n",
    "\n",
    "                    # Version B: Save FEN + Move\n",
    "                    with open(fen_move_dir / \"texts\" / f\"{idx}.txt\", \"w\", encoding=\"utf-8\") as ftxt:\n",
    "                        ftxt.write(f\"{fen} | Next move: {move_uci}\")\n",
    "\n",
    "                    board.push(move)\n",
    "                    idx += 1\n",
    "\n",
    "            logging.info(f\"✅ Successfully created {idx} examples in '{out_dir}'\")\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        logging.error(f\"Error: The file at {pgn_path} was not found.\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"An unexpected error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PWXAUuzh404x",
    "outputId": "4b887158-01d3-4d27-fc05-1fb03ecb56d8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing dataset_loader.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile dataset_loader.py\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "import clip\n",
    "\n",
    "class ChessDataset(Dataset):\n",
    "    \"\"\"\n",
    "    A PyTorch Dataset for loading chess board images and their corresponding FEN notations.\n",
    "    \"\"\"\n",
    "    def __init__(self, data_dir: str, preprocess):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            data_dir (str): Path to the dataset directory which contains 'images' and 'texts' subdirectories.\n",
    "            preprocess: The image preprocessing function from CLIP.\n",
    "        \"\"\"\n",
    "        self.data_dir = Path(data_dir)\n",
    "        self.image_paths = sorted(list((self.data_dir / \"images\").glob(\"*.png\")))\n",
    "        self.text_paths = sorted(list((self.data_dir / \"texts\").glob(\"*.txt\")))\n",
    "        self.preprocess = preprocess\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx: int):\n",
    "        # Load image\n",
    "        image = Image.open(self.image_paths[idx]).convert(\"RGB\")\n",
    "        image = self.preprocess(image)\n",
    "\n",
    "        # Load text\n",
    "        with open(self.text_paths[idx], \"r\", encoding=\"utf-8\") as f:\n",
    "            text = f.read().strip()\n",
    "\n",
    "        # Tokenize text\n",
    "        tokenized_text = clip.tokenize([text])[0]\n",
    "\n",
    "        return image, tokenized_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9CsnMAba44is",
    "outputId": "465e23bb-3124-42d1-9de0-5631f19960e1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing train_clip.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile train_clip.py\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import clip\n",
    "from dataset_loader import ChessDataset\n",
    "import argparse\n",
    "from pathlib import Path\n",
    "import logging\n",
    "\n",
    "# Setup basic logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "def train_clip_model(data_dir: str, save_path: str, epochs: int, batch_size: int, lr: float, split_ratio: float):\n",
    "    \"\"\"\n",
    "    Trains a CLIP model on the chess dataset.\n",
    "\n",
    "    Args:\n",
    "        data_dir (str): Directory of the dataset.\n",
    "        save_path (str): Directory to save model checkpoints.\n",
    "        epochs (int): Number of training epochs.\n",
    "        batch_size (int): Batch size for training.\n",
    "        lr (float): Learning rate for the optimizer.\n",
    "        split_ratio (float): Ratio of training data to total data.\n",
    "    \"\"\"\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    logging.info(f\"Using device: {device}\")\n",
    "\n",
    "    # Ensure save directory exists\n",
    "    Path(save_path).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    model, preprocess = clip.load(\"ViT-B/32\", device=device, jit=False)\n",
    "\n",
    "    dataset = ChessDataset(data_dir, preprocess)\n",
    "\n",
    "    # Splitting the dataset\n",
    "    train_size = int(len(dataset) * split_ratio)\n",
    "    val_size = len(dataset) - train_size\n",
    "    train_set, val_set = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "    train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
    "    val_loader = DataLoader(val_set, batch_size=batch_size, shuffle=False, num_workers=4, pin_memory=True)\n",
    "\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr, betas=(0.9,0.98), eps=1e-6, weight_decay=0.2)\n",
    "    loss_img = nn.CrossEntropyLoss()\n",
    "    loss_txt = nn.CrossEntropyLoss()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        total_loss = 0.0\n",
    "        for images, texts in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs}\"):\n",
    "            images = images.to(device)\n",
    "            texts = texts.to(device)\n",
    "\n",
    "            logits_per_image, logits_per_text = model(images, texts)\n",
    "            ground_truth = torch.arange(len(images), dtype=torch.long, device=device)\n",
    "\n",
    "            loss = (loss_img(logits_per_image, ground_truth) + loss_txt(logits_per_text, ground_truth)) / 2\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        avg_train_loss = total_loss / len(train_loader)\n",
    "        logging.info(f\"Epoch [{epoch+1}/{epochs}] Training Loss: {avg_train_loss:.4f}\")\n",
    "\n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        total_val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for images, texts in tqdm(val_loader, desc=\"Validating\"):\n",
    "                images = images.to(device)\n",
    "                texts = texts.to(device)\n",
    "                logits_per_image, logits_per_text = model(images, texts)\n",
    "                ground_truth = torch.arange(len(images), dtype=torch.long, device=device)\n",
    "                loss = (loss_img(logits_per_image, ground_truth) + loss_txt(logits_per_text, ground_truth)) / 2\n",
    "                total_val_loss += loss.item()\n",
    "\n",
    "        avg_val_loss = total_val_loss / len(val_loader)\n",
    "        logging.info(f\"Epoch [{epoch+1}/{epochs}] Validation Loss: {avg_val_loss:.4f}\")\n",
    "\n",
    "        # Save model checkpoint\n",
    "        torch.save(model.state_dict(), f\"{save_path}/clip_chess_epoch_{epoch+1}.pt\")\n",
    "\n",
    "    logging.info(\"✅ Training complete.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser(description=\"Train a CLIP model on chess data.\")\n",
    "    parser.add_argument(\"data_dir\", type=str, help=\"Directory of the dataset.\")\n",
    "    parser.add_argument(\"save_path\", type=str, help=\"Directory to save model checkpoints.\")\n",
    "    parser.add_argument(\"--epochs\", type=int, default=5, help=\"Number of training epochs.\")\n",
    "    parser.add_argument(\"--batch_size\", type=int, default=64, help=\"Batch size for training.\")\n",
    "    parser.add_argument(\"--lr\", type=float, default=5e-6, help=\"Learning rate.\")\n",
    "    parser.add_argument(\"--split_ratio\", type=float, default=0.9, help=\"Training/validation split ratio.\")\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    train_clip_model(args.data_dir, args.save_path, args.epochs, args.batch_size, args.lr, args.split_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "tW7CmwdI49DF"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"D:\\vivek_projects\\vichar\\vichar-clip\\Notebooks\\dataset_prep.py\", line 3, in <module>\n",
      "    import cairosvg\n",
      "  File \"C:\\Users\\admin\\miniconda3\\envs\\pytorch_5070ti\\lib\\site-packages\\cairosvg\\__init__.py\", line 25, in <module>\n",
      "    from . import surface  # noqa isort:skip\n",
      "  File \"C:\\Users\\admin\\miniconda3\\envs\\pytorch_5070ti\\lib\\site-packages\\cairosvg\\surface.py\", line 9, in <module>\n",
      "    import cairocffi as cairo\n",
      "  File \"C:\\Users\\admin\\miniconda3\\envs\\pytorch_5070ti\\lib\\site-packages\\cairocffi\\__init__.py\", line 60, in <module>\n",
      "    cairo = dlopen(\n",
      "  File \"C:\\Users\\admin\\miniconda3\\envs\\pytorch_5070ti\\lib\\site-packages\\cairocffi\\__init__.py\", line 57, in dlopen\n",
      "    raise OSError(error_message)  # pragma: no cover\n",
      "OSError: no library called \"cairo-2\" was found\n",
      "no library called \"cairo\" was found\n",
      "no library called \"libcairo-2\" was found\n",
      "cannot load library 'libcairo.so.2': error 0x7e.  Additionally, ctypes.util.find_library() did not manage to locate a library called 'libcairo.so.2'\n",
      "cannot load library 'libcairo.2.dylib': error 0x7e.  Additionally, ctypes.util.find_library() did not manage to locate a library called 'libcairo.2.dylib'\n",
      "cannot load library 'libcairo-2.dll': error 0x7e.  Additionally, ctypes.util.find_library() did not manage to locate a library called 'libcairo-2.dll'\n"
     ]
    }
   ],
   "source": [
    "!python dataset_prep.py lichess_games.pgn ./datasets --max_games 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rnJiM6qR5Bad",
    "outputId": "f13884e3-93d9-4f83-af34-c1057ff76094"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 11:57:59,377 - INFO - Using device: cuda\n",
      "2025-08-18 11:58:04,998 - INFO - Successfully found 30166 examples in the dataset.\n",
      "Epoch 1/5 Training: 100% 849/849 [03:20<00:00,  4.24it/s]\n",
      "2025-08-18 12:01:25,461 - INFO - Epoch [1/5] Training Loss: 0.3262\n",
      "Epoch 1/5 Validating: 100% 95/95 [00:17<00:00,  5.34it/s]\n",
      "2025-08-18 12:01:43,257 - INFO - Epoch [1/5] Validation Loss: 0.0785\n",
      "Epoch 2/5 Training: 100% 849/849 [03:18<00:00,  4.28it/s]\n",
      "2025-08-18 12:05:02,848 - INFO - Epoch [2/5] Training Loss: 0.0703\n",
      "Epoch 2/5 Validating: 100% 95/95 [00:17<00:00,  5.40it/s]\n",
      "2025-08-18 12:05:20,444 - INFO - Epoch [2/5] Validation Loss: 0.0408\n",
      "Epoch 3/5 Training: 100% 849/849 [03:14<00:00,  4.37it/s]\n",
      "2025-08-18 12:08:35,650 - INFO - Epoch [3/5] Training Loss: 0.0441\n",
      "Epoch 3/5 Validating: 100% 95/95 [00:17<00:00,  5.37it/s]\n",
      "2025-08-18 12:08:53,327 - INFO - Epoch [3/5] Validation Loss: 0.0336\n",
      "Epoch 4/5 Training: 100% 849/849 [03:12<00:00,  4.42it/s]\n",
      "2025-08-18 12:12:06,434 - INFO - Epoch [4/5] Training Loss: 0.0408\n",
      "Epoch 4/5 Validating: 100% 95/95 [00:18<00:00,  5.05it/s]\n",
      "2025-08-18 12:12:25,242 - INFO - Epoch [4/5] Validation Loss: 0.0422\n",
      "Epoch 5/5 Training: 100% 849/849 [03:13<00:00,  4.39it/s]\n",
      "2025-08-18 12:15:39,416 - INFO - Epoch [5/5] Training Loss: 0.0369\n",
      "Epoch 5/5 Validating: 100% 95/95 [00:17<00:00,  5.45it/s]\n",
      "2025-08-18 12:15:56,836 - INFO - Epoch [5/5] Validation Loss: 0.0414\n",
      "2025-08-18 12:15:57,565 - INFO - ✅ Training complete.\n"
     ]
    }
   ],
   "source": [
    "!python train_clip.py ./datasets/fen_only ./checkpoints/fen_only_model --epochs 5 --batch_size 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ImI5i9rK5EeF",
    "outputId": "870be768-a31d-4e11-9e56-fdcf20b93acb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting dataset_prep.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile dataset_prep.py\n",
    "import chess.pgn\n",
    "import chess.svg\n",
    "import cairosvg\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import logging\n",
    "import argparse\n",
    "\n",
    "# ======================================================================\n",
    "# Setup more verbose logging to see all levels of messages\n",
    "# ======================================================================\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "def pgn_to_examples(pgn_path: str, out_dir: str, max_games: int):\n",
    "    \"\"\"\n",
    "    Processes a PGN file to generate image-text pairs for training a CLIP model on chess positions.\n",
    "    \"\"\"\n",
    "    logging.info(\"--- Starting Dataset Preparation ---\")\n",
    "\n",
    "    # --- Step 1: Validate PGN file existence ---\n",
    "    pgn_file = Path(pgn_path)\n",
    "    if not pgn_file.exists():\n",
    "        logging.error(f\"FATAL ERROR: The input PGN file was not found at the specified path: '{pgn_path}'\")\n",
    "        logging.error(\"Please check if the file name and path are correct.\")\n",
    "        return # Exit the function immediately\n",
    "\n",
    "    logging.info(f\"Found PGN file: '{pgn_path}'\")\n",
    "\n",
    "    # --- Step 2: Set up output directories ---\n",
    "    out_dir = Path(out_dir)\n",
    "    fen_only_dir = out_dir / \"fen_only\"\n",
    "    fen_move_dir = out_dir / \"fen_move\"\n",
    "\n",
    "    try:\n",
    "        logging.info(f\"Creating output directory: '{fen_only_dir}'\")\n",
    "        (fen_only_dir / \"images\").mkdir(parents=True, exist_ok=True)\n",
    "        (fen_only_dir / \"texts\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        logging.info(f\"Creating output directory: '{fen_move_dir}'\")\n",
    "        (fen_move_dir / \"images\").mkdir(parents=True, exist_ok=True)\n",
    "        (fen_move_dir / \"texts\").mkdir(parents=True, exist_ok=True)\n",
    "        logging.info(\"Successfully created/verified output directories.\")\n",
    "    except PermissionError:\n",
    "        logging.error(f\"FATAL ERROR: Permission denied to create directories in '{out_dir}'.\")\n",
    "        logging.error(\"Please check your write permissions for this location.\")\n",
    "        return\n",
    "    except Exception as e:\n",
    "        logging.error(f\"FATAL ERROR: An unexpected error occurred while creating directories: {e}\")\n",
    "        return\n",
    "\n",
    "    # --- Step 3: Process the PGN file ---\n",
    "    try:\n",
    "        with open(pgn_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            game_count = 0\n",
    "            total_examples = 0\n",
    "\n",
    "            # Use tqdm to show progress over the number of games\n",
    "            with tqdm(total=max_games, desc=\"Processing games\") as pbar:\n",
    "                while True:\n",
    "                    # Check if we have reached the desired number of games\n",
    "                    if game_count >= max_games:\n",
    "                        logging.info(f\"Reached the max_games limit of {max_games}.\")\n",
    "                        break\n",
    "\n",
    "                    game = chess.pgn.read_game(f)\n",
    "\n",
    "                    if game is None:\n",
    "                        logging.warning(\"Finished reading all games from the PGN file before reaching max_games limit.\")\n",
    "                        break\n",
    "\n",
    "                    board = game.board()\n",
    "                    # Iterate through moves and create examples\n",
    "                    for move in game.mainline_moves():\n",
    "                        fen = board.fen()\n",
    "                        move_uci = move.uci()\n",
    "\n",
    "                        # Generate and save the board image\n",
    "                        svg_data = chess.svg.board(board=board, size=350)\n",
    "                        try:\n",
    "                            png_bytes = cairosvg.svg2png(bytestring=svg_data.encode(\"utf-8\"))\n",
    "\n",
    "                            # Save image for FEN only dataset\n",
    "                            img_path_fen_only = fen_only_dir / \"images\" / f\"{total_examples}.png\"\n",
    "                            with open(img_path_fen_only, \"wb\") as img_file:\n",
    "                                img_file.write(png_bytes)\n",
    "\n",
    "                            # Save image for FEN + move dataset\n",
    "                            img_path_fen_move = fen_move_dir / \"images\" / f\"{total_examples}.png\"\n",
    "                            with open(img_path_fen_move, \"wb\") as img_file:\n",
    "                                img_file.write(png_bytes)\n",
    "\n",
    "                        except Exception as e:\n",
    "                            logging.error(f\"Failed to convert SVG to PNG for position at index {total_examples}: {e}\")\n",
    "                            board.push(move) # Still push the move to continue correctly\n",
    "                            continue\n",
    "\n",
    "                        # Version A: Save FEN only\n",
    "                        with open(fen_only_dir / \"texts\" / f\"{total_examples}.txt\", \"w\", encoding=\"utf-8\") as ftxt:\n",
    "                            ftxt.write(fen)\n",
    "\n",
    "                        # Version B: Save FEN + Move\n",
    "                        with open(fen_move_dir / \"texts\" / f\"{total_examples}.txt\", \"w\", encoding=\"utf-8\") as ftxt:\n",
    "                            ftxt.write(f\"{fen} | Next move: {move_uci}\")\n",
    "\n",
    "                        board.push(move)\n",
    "                        total_examples += 1\n",
    "\n",
    "                    game_count += 1\n",
    "                    pbar.update(1) # Update progress bar for each game processed\n",
    "\n",
    "            logging.info(f\"--- Dataset Preparation Complete ---\")\n",
    "            logging.info(f\"Processed {game_count} games.\")\n",
    "            logging.info(f\"✅ Successfully created {total_examples} image-text pair examples in '{out_dir}'\")\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.error(f\"An unexpected error occurred during PGN processing: {e}\", exc_info=True)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    parser = argparse.ArgumentParser(description=\"Generate image-text datasets from a PGN chess file.\")\n",
    "    parser.add_argument(\"pgn_path\", type=str, help=\"Path to the input PGN file.\")\n",
    "    parser.add_argument(\"out_dir\", type=str, help=\"The root directory to save the generated datasets.\")\n",
    "    parser.add_argument(\"--max_games\", type=int, default=1000, help=\"Maximum number of games to process from the PGN file.\")\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    pgn_to_examples(args.pgn_path, args.out_dir, args.max_games)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "!conda activate pytorch_5070ti\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !conda install -c conda-forge cairosvg cairocffi cairo pango gdk-pixbuf tinycss2 cssselect2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VjQk5y9X7U6u",
    "outputId": "24609e22-4984-4567-da23-39e98c659437"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"D:\\vivek_projects\\vichar\\vichar-clip\\Notebooks\\dataset_prep.py\", line 3, in <module>\n",
      "    import cairosvg\n",
      "  File \"C:\\Users\\admin\\miniconda3\\envs\\pytorch_5070ti\\lib\\site-packages\\cairosvg\\__init__.py\", line 25, in <module>\n",
      "    from . import surface  # noqa isort:skip\n",
      "  File \"C:\\Users\\admin\\miniconda3\\envs\\pytorch_5070ti\\lib\\site-packages\\cairosvg\\surface.py\", line 9, in <module>\n",
      "    import cairocffi as cairo\n",
      "  File \"C:\\Users\\admin\\miniconda3\\envs\\pytorch_5070ti\\lib\\site-packages\\cairocffi\\__init__.py\", line 60, in <module>\n",
      "    cairo = dlopen(\n",
      "  File \"C:\\Users\\admin\\miniconda3\\envs\\pytorch_5070ti\\lib\\site-packages\\cairocffi\\__init__.py\", line 57, in dlopen\n",
      "    raise OSError(error_message)  # pragma: no cover\n",
      "OSError: no library called \"cairo-2\" was found\n",
      "no library called \"libcairo-2\" was found\n",
      "cannot load library 'C:\\Users\\admin\\miniconda3\\envs\\pytorch_5070ti\\Library\\bin\\cairo.dll': error 0x7e\n",
      "cannot load library 'libcairo.so.2': error 0x7e.  Additionally, ctypes.util.find_library() did not manage to locate a library called 'libcairo.so.2'\n",
      "cannot load library 'libcairo.2.dylib': error 0x7e.  Additionally, ctypes.util.find_library() did not manage to locate a library called 'libcairo.2.dylib'\n",
      "cannot load library 'libcairo-2.dll': error 0x7e.  Additionally, ctypes.util.find_library() did not manage to locate a library called 'libcairo-2.dll'\n"
     ]
    }
   ],
   "source": [
    "!python dataset_prep.py lichess_games_2013-01.pgn ./datasets --max_games 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kALjzo907bF6",
    "outputId": "94f8cbc9-1fbb-40ba-f40a-f63fbb4cbc2d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 12:17:32,579 - INFO - Using device: cuda\n",
      "2025-08-18 12:17:37,564 - INFO - Successfully found 30166 examples in the dataset.\n",
      "Epoch 1/5 Training: 100% 849/849 [03:34<00:00,  3.96it/s]\n",
      "2025-08-18 12:21:11,739 - INFO - Epoch [1/5] Training Loss: 0.4330\n",
      "Epoch 1/5 Validating: 100% 95/95 [00:18<00:00,  5.06it/s]\n",
      "2025-08-18 12:21:30,520 - INFO - Epoch [1/5] Validation Loss: 0.1398\n",
      "Epoch 2/5 Training: 100% 849/849 [03:26<00:00,  4.11it/s]\n",
      "2025-08-18 12:24:58,027 - INFO - Epoch [2/5] Training Loss: 0.0761\n",
      "Epoch 2/5 Validating: 100% 95/95 [00:17<00:00,  5.31it/s]\n",
      "2025-08-18 12:25:15,906 - INFO - Epoch [2/5] Validation Loss: 0.0542\n",
      "Epoch 3/5 Training: 100% 849/849 [03:14<00:00,  4.37it/s]\n",
      "2025-08-18 12:28:30,882 - INFO - Epoch [3/5] Training Loss: 0.0476\n",
      "Epoch 3/5 Validating: 100% 95/95 [00:18<00:00,  5.08it/s]\n",
      "2025-08-18 12:28:49,586 - INFO - Epoch [3/5] Validation Loss: 0.0430\n",
      "Epoch 4/5 Training: 100% 849/849 [03:12<00:00,  4.41it/s]\n",
      "2025-08-18 12:32:03,014 - INFO - Epoch [4/5] Training Loss: 0.0393\n",
      "Epoch 4/5 Validating: 100% 95/95 [00:18<00:00,  5.20it/s]\n",
      "2025-08-18 12:32:21,283 - INFO - Epoch [4/5] Validation Loss: 0.0352\n",
      "Epoch 5/5 Training: 100% 849/849 [03:15<00:00,  4.34it/s]\n",
      "2025-08-18 12:35:37,704 - INFO - Epoch [5/5] Training Loss: 0.0369\n",
      "Epoch 5/5 Validating: 100% 95/95 [00:18<00:00,  5.10it/s]\n",
      "2025-08-18 12:35:56,342 - INFO - Epoch [5/5] Validation Loss: 0.0404\n",
      "2025-08-18 12:35:57,261 - INFO - ✅ Training complete.\n"
     ]
    }
   ],
   "source": [
    "!python train_clip.py ./datasets/fen_move ./checkpoints/fen_move_model --epochs 5 --batch_size 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "foASV3StHPt4"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from google.colab import files\n",
    "import logging\n",
    "\n",
    "# --- Step 1: Zip the checkpoints folder ---\n",
    "\n",
    "# Define the folder to be zipped and the name of the output zip file\n",
    "folder_to_zip = './checkpoints'\n",
    "zip_filename = 'checkpoints.zip'\n",
    "\n",
    "logging.info(f\"Attempting to zip the folder: '{folder_to_zip}'\")\n",
    "\n",
    "# Check if the folder actually exists\n",
    "if os.path.isdir(folder_to_zip):\n",
    "    # The '!' allows us to run a shell command directly in Colab.\n",
    "    # -r means 'recursive' (include all subdirectories)\n",
    "    # -q means 'quiet' (to keep the output clean)\n",
    "    get_ipython().system(f\"zip -r -q {zip_filename} {folder_to_zip}\")\n",
    "\n",
    "    logging.info(f\"Successfully created zip file: '{zip_filename}'\")\n",
    "\n",
    "    # --- Step 2: Download the created zip file ---\n",
    "    logging.info(\"Starting download... Please wait for your browser to prompt you to save the file.\")\n",
    "\n",
    "    try:\n",
    "        files.download(zip_filename)\n",
    "        logging.info(\"Download command issued successfully.\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"An error occurred during download: {e}\")\n",
    "\n",
    "else:\n",
    "    logging.error(f\"Error: The folder '{folder_to_zip}' does not exist in the current directory.\")\n",
    "    logging.error(\"Please make sure your training script has run and created the checkpoints.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "DtvCgCPPLiNS"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatgpt_Clip.ipynb\n",
      "checkpoints\n",
      "checkpoints.zip\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
